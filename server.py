import json
import time
import uuid
from typing import Dict, Optional, Tuple

from fastapi import FastAPI, WebSocket, WebSocketDisconnect

app = FastAPI()

# =========================================================
# GPU Registry
# =========================================================
# gpu_id -> {
#   ws: WebSocket,
#   status: "idle" | "busy",
#   last_heartbeat: float,
#   current_task: Optional[str]
# }
gpu_registry: Dict[str, dict] = {}

# task_id -> frontend websocket
task_frontend_map: Dict[str, WebSocket] = {}

# task_id -> gpu_id (for debugging / optional future use)
task_gpu_map: Dict[str, str] = {}


# =========================================================
# Command Builder
# =========================================================
def build_torchrun_command(payload: dict) -> str:
    """
    æ„å»º torchrun å‘½ä»¤ï¼š
    - ref_image ä¸º None æ—¶ï¼Œä¸ä¼  --cond_type / --ref
    """
    p = payload["parameters"]

    cmd = [
        "torchrun",
        "--nproc_per_node", "1",
        "--standalone",
        "scripts/diffusion/inference.py",
        p["config"],
        "--save-dir", "outputs/videodemo5",
        "--prompt", f"\"{p['prompt']}\"",
        "--sampling_option.num_steps", str(p["steps"]),
        "--sampling_option.num_frames", str(p["frames"]),
        "--sampling_option.aspect_ratio", p["ratio"],
        "--fps_save", str(p["fps"]),
    ]

    # âœ… åªæœ‰å­˜åœ¨ ref_image æ—¶æ‰åŠ  cond_type / ref
    if p.get("ref_image"):
        cmd.extend([
            "--cond_type", p["cond"],
            "--ref", p["ref_image"]
        ])

    return " ".join(cmd)


# =========================================================
# Scheduler
# =========================================================
def select_idle_gpu() -> Tuple[Optional[str], Optional[dict]]:
    # ç®€å•ç­–ç•¥ï¼šé€‰ç¬¬ä¸€ä¸ª idle GPU
    for gpu_id, info in gpu_registry.items():
        if info["status"] == "idle":
            return gpu_id, info
    return None, None


# =========================================================
# GPU WebSocket (reverse)
# =========================================================
@app.websocket("/ws/gpu")
async def gpu_ws(ws: WebSocket):
    await ws.accept()

    # ---------- æ³¨å†Œ ----------
    try:
        register_msg = json.loads(await ws.receive_text())
    except Exception:
        await ws.close(code=1008)
        return

    gpu_id = register_msg.get("gpu_id")
    if not gpu_id:
        await ws.close(code=1008)
        return

    gpu_registry[gpu_id] = {
        "ws": ws,
        "status": "idle",
        "last_heartbeat": time.time(),
        "current_task": None,
    }

    print(f"ğŸ”¥ GPU registered: {gpu_id}")

    try:
        while True:
            msg = json.loads(await ws.receive_text())
            msg_type = msg.get("type")

            # ---------- å¿ƒè·³ ----------
            if msg_type == "heartbeat":
                gpu_registry[gpu_id]["last_heartbeat"] = time.time()

            # ---------- å®æ—¶æ—¥å¿— ----------
            elif msg_type == "TASK_LOG":
                task_id = msg.get("task_id")
                frontend_ws = task_frontend_map.get(task_id)
                if frontend_ws:
                    # åŸæ ·è½¬å‘ç»™å‰ç«¯
                    await frontend_ws.send_text(json.dumps(msg))
                else:
                    # å‰ç«¯å¯èƒ½å·²æ–­å¼€/é‡è¿ï¼›è¿™é‡Œå…ˆæ‰“å°ï¼Œæ–¹ä¾¿å®šä½
                    #ï¼ˆåç»­å¯å‡çº§ä¸º session_id æ–¹æ¡ˆé¿å…ä¸¢æ¶ˆæ¯ï¼‰
                    print(f"âš ï¸ No frontend ws for TASK_LOG, task_id={task_id}")

            # ---------- ä»»åŠ¡å®Œæˆï¼ˆå« public_urlï¼‰ ----------
            elif msg_type == "task_finished":
                task_id = msg.get("task_id")

                # GPU çŠ¶æ€æ¢å¤
                if gpu_id in gpu_registry:
                    gpu_registry[gpu_id]["status"] = "idle"
                    gpu_registry[gpu_id]["current_task"] = None

                print(f"âœ… GPU {gpu_id} finished task {task_id}")
                print("ğŸ“¦ GPU RETURN PAYLOAD:")
                print(json.dumps(msg, ensure_ascii=False, indent=2))

                frontend_ws = task_frontend_map.pop(task_id, None)
                task_gpu_map.pop(task_id, None)

                if frontend_ws:
                    print("ğŸ“¤ Forwarding task_finished to frontend (passthrough)")
                    # âœ… åŸæ ·é€ä¼ ï¼Œä¸åŒ…ã€ä¸æ”¹
                    await frontend_ws.send_text(json.dumps(msg))
                else:
                    print(f"âš ï¸ No frontend websocket found for task {task_id}")

            else:
                print(f"âš ï¸ Unknown GPU message type: {msg_type}")

    except WebSocketDisconnect:
        # GPU æ–­å¼€
        gpu_registry.pop(gpu_id, None)
        print(f"âŒ GPU disconnected: {gpu_id}")
    except Exception as e:
        gpu_registry.pop(gpu_id, None)
        print(f"ğŸ”¥ GPU error ({gpu_id}): {e}")


# =========================================================
# Frontend WebSocket
# =========================================================
@app.websocket("/ws")
async def frontend_ws(ws: WebSocket):
    await ws.accept()
    print("âœ… Frontend connected")

    try:
        while True:
            raw = await ws.receive_text()
            data = json.loads(raw)

            if data.get("type") != "TASK_EXECUTION":
                await ws.send_text(json.dumps({
                    "type": "IGNORED",
                    "message": "Unsupported message type"
                }))
                continue

            # ---------- è°ƒåº¦ GPU ----------
            gpu_id, gpu = select_idle_gpu()
            if not gpu:
                await ws.send_text(json.dumps({
                    "type": "TASK_REJECTED",
                    "message": "No idle GPU available"
                }))
                continue

            # ---------- æ„å»ºä»»åŠ¡ ----------
            task_id = str(uuid.uuid4())
            command = build_torchrun_command(data)

            gpu["status"] = "busy"
            gpu["current_task"] = task_id

            task_frontend_map[task_id] = ws
            task_gpu_map[task_id] = gpu_id

            print(f"ğŸ“¤ Dispatch task {task_id} to GPU {gpu_id}")
            print("ğŸ§  Torchrun command:")
            print(command)

            # ---------- å‘é€ç»™ GPU ----------
            await gpu["ws"].send_text(json.dumps({
                "type": "exec_command",
                "task_id": task_id,
                "command": command
            }))

            # ---------- Ack å‰ç«¯ ----------
            await ws.send_text(json.dumps({
                "type": "TASK_ACCEPTED",
                "task_id": task_id,
                "gpu_id": gpu_id
            }))

    except WebSocketDisconnect:
        print("âŒ Frontend disconnected")
        # å¯é€‰ï¼šæ¸…ç†è¯¥ ws ç›¸å…³çš„ task æ˜ å°„ï¼ˆè¿™é‡Œä¿å®ˆä¸æ¸…ç†ï¼Œé¿å…è¯¯åˆ ï¼‰
    except Exception as e:
        print("ğŸ”¥ Frontend WS error:", e)
