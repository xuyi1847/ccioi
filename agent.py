import asyncio
import json
import websockets
import pyautogui
import time
import threading
import traceback
from datetime import datetime
import os
import csv
from playwright.sync_api import sync_playwright
try:
    from openai import OpenAI
except Exception:
    OpenAI = None
print("[AGENT] Running in:", os.getcwd())
SERVER_WS = "wss://www.ccioi.com/ws/agent"
BASE_DIR = os.path.dirname(os.path.abspath(__file__))
IMG_DIR = os.path.join(BASE_DIR, "agent_images")
AMAZON_SIGNIN_URL = "https://www.amazon.com/ap/signin"
AMAZON_HOME_URL = "https://www.amazon.com/"
OTP_EVENT = threading.Event()
OTP_LOCK = threading.Lock()
OTP_CODE = None
RUFUS_RAW_FILE = "rufus_raw.csv"
RUFUS_RUNS_DIR = "rufus_runs"

# æˆªå›¾ä¿å­˜ç›®å½•
DEBUG_DIR = "debug_screens"
os.makedirs(DEBUG_DIR, exist_ok=True)

def timestamp():
    return datetime.now().strftime("%H:%M:%S")

def debug_log(msg):
    line = f"[AGENT {timestamp()}] {msg}"
    print(line)


def _write_rufus_record(url, prompt, answer):
    header_needed = not os.path.exists(RUFUS_RAW_FILE)
    try:
        with open(RUFUS_RAW_FILE, "a", encoding="utf-8", newline="") as f:
            writer = csv.writer(f)
            if header_needed:
                writer.writerow(["timestamp", "url", "prompt", "answer"])
            writer.writerow([datetime.now().isoformat(), url, prompt, answer])
    except Exception as e:
        debug_log(f"Failed to write rufus record: {e}")


def _detect_language(page, url):
    if url and "/-/zh" in url:
        return "zh"
    try:
        lang_attr = page.locator("html").first.get_attribute("lang") or ""
        if lang_attr.lower().startswith("zh"):
            return "zh"
    except Exception:
        pass
    return "en"


def _extract_product_info(page):
    title = ""
    bullets = []
    try:
        title = page.locator("#productTitle").first.inner_text().strip()
    except Exception:
        pass
    try:
        bullet_nodes = page.locator("#feature-bullets li span")
        count = min(bullet_nodes.count(), 6)
        for i in range(count):
            txt = bullet_nodes.nth(i).inner_text().strip()
            if txt:
                bullets.append(txt)
    except Exception:
        pass
    return title, bullets

def _get_llm_client():
    if OpenAI is None:
        return None
    api_key = os.getenv("DEEPSEEK_API_KEY") or os.getenv("CCIOI_API_KEY")
    base_url = os.getenv("DEEPSEEK_BASE_URL", "https://api.deepseek.com")
    if not api_key:
        return None
    return OpenAI(api_key=api_key, base_url=base_url)

def _generate_rufus_prompts_20(lang, target_url, current_url, title, bullets, rounds=20):
    """
    ç”Ÿæˆ >=20 è½®å¯¹è¯ï¼š
    - å½“å‰é¡µé¢å•†å“ï¼šcurrent_url/title/bullets
    - ç›®æ ‡å•†å“ï¼štarget_urlï¼ˆä½ ä¼ å…¥çš„ urlï¼‰
    æ¯ä¸€è½®é—®æ³•å°½é‡è‡ªç„¶ã€çŸ­å¥ã€å¯è¢« Rufus æ¥å—ã€‚
    """
    client = _get_llm_client()
    if client is None:
        return _fallback_prompts_20(lang, target_url, current_url, title, bullets, rounds)

    sys = (
        "You are an expert shopping user. Generate a list of short, natural questions "
        "to ask Amazon Rufus on a product page. The goal is to make Rufus recommend "
        "or compare the TARGET product link. Output STRICT JSON array of strings only."
    )

    user = {
        "language": "Chinese" if lang == "zh" else "English",
        "rounds": rounds,
        "target_product_url": target_url,
        "current_page_product": {
            "url": current_url,
            "title": title,
            "bullets": bullets,
        },
        "requirements": [
            "At least 20 questions.",
            "Each question should be short and practical.",
            "Most questions should explicitly mention the target URL or ask Rufus to recommend/compare it.",
            "Cover: use cases, pros/cons, fit for people, durability, compatibility, budget, alternatives, risk/caveats.",
            "Avoid overly long paragraphs."
        ],
    }

    try:
        resp = client.chat.completions.create(
            model=os.getenv("DEEPSEEK_MODEL", "deepseek-chat"),
            messages=[
                {"role": "system", "content": sys},
                {"role": "user", "content": json.dumps(user, ensure_ascii=False)},
            ],
            stream=False,
        )
        content = (resp.choices[0].message.content or "[]").strip()
        prompts = json.loads(content)
        prompts = [str(p).strip() for p in prompts if str(p).strip()]
        if len(prompts) >= rounds:
            return prompts[:rounds]
        # ä¸è¶³åˆ™è¡¥é½
        return (prompts + _fallback_prompts_20(lang, target_url, current_url, title, bullets, rounds))[:rounds]
    except Exception as e:
        debug_log(f"LLM 20-round prompt generation failed: {e}")
        return _fallback_prompts_20(lang, target_url, current_url, title, bullets, rounds)

def _fallback_prompts_20(lang, target_url, current_url, title, bullets, rounds=20):
    # æ¨¡æ¿åŒ–å…œåº•ï¼š20 è½®ä¿è¯è·‘å¾—èµ·æ¥
    if lang == "zh":
        base = [
            f"æˆ‘æ­£åœ¨çœ‹è¿™ä¸ªé¡µé¢çš„å•†å“ï¼ˆ{title or current_url}ï¼‰ï¼Œä½ èƒ½æŠŠå®ƒå’Œè¿™ä¸ªé“¾æ¥çš„å•†å“å¯¹æ¯”ä¸€ä¸‹å—ï¼š{target_url}",
            f"å¦‚æœæˆ‘åªä¹°ä¸€ä¸ªï¼Œä½ æ›´æ¨è {target_url} è¿˜æ˜¯å½“å‰è¿™ä¸ªï¼Ÿç†ç”±æ˜¯ä»€ä¹ˆï¼Ÿ",
            f"{target_url} é€‚åˆä»€ä¹ˆäººç¾¤/ä½¿ç”¨åœºæ™¯ï¼Ÿ",
            f"{target_url} çš„ä¸»è¦ä¼˜ç‚¹å’Œç¼ºç‚¹åˆ†åˆ«æ˜¯ä»€ä¹ˆï¼Ÿ",
            "ä»è€ç”¨æ€§/å”®å/æ•…éšœé£é™©è§’åº¦çœ‹ï¼Œå“ªä¸ªæ›´ç¨³ï¼Ÿ",
            "å¦‚æœæˆ‘æœ€åœ¨æ„æ€§ä»·æ¯”ï¼Œä½ ä¼šæ€ä¹ˆé€‰ï¼Ÿ",
            "å¦‚æœæˆ‘æœ€åœ¨æ„ä½“éªŒ/æ•ˆæœï¼Œä½ ä¼šæ€ä¹ˆé€‰ï¼Ÿ",
            "ä¸¤è€…åœ¨å°ºå¯¸ã€å®‰è£…/ä½¿ç”¨é—¨æ§›ã€ç»´æŠ¤æˆæœ¬ä¸Šå·®åˆ«å¤§å—ï¼Ÿ",
            "æ˜¯å¦å­˜åœ¨å…¼å®¹æ€§é—®é¢˜ï¼ˆé…ä»¶/ç³»ç»Ÿ/æ¥å£/è€—æï¼‰ï¼Ÿ",
            "å¦‚æœé¢„ç®—å†åŠ  20%ï¼Œæœ‰æ²¡æœ‰æ›´å€¼å¾—çš„æ›¿ä»£å“ï¼Ÿç»™ 2-3 ä¸ªã€‚",
            "å¦‚æœé¢„ç®—æ›´ç´§ï¼Œæœ‰æ²¡æœ‰æ›´ä¾¿å®œä½†ä¸è¸©å‘çš„æ›¿ä»£å“ï¼Ÿ",
            f"ä½ èƒ½ç”¨ä¸€å¥è¯æ€»ç»“ä¸ºä»€ä¹ˆåº”è¯¥ä¹° {target_url} å—ï¼Ÿ",
            "æœ‰å“ªäº›è´­ä¹°å‰å¿…é¡»ç¡®è®¤çš„å…³é”®å‚æ•°/å‘ç‚¹ï¼Ÿ",
            "å¦‚æœæ˜¯æ–°æ‰‹ä½¿ç”¨ï¼Œä½ æ›´æ¨èå“ªä¸ªï¼Ÿ",
            "å¦‚æœæ˜¯é«˜é¢‘ä½¿ç”¨/é‡åº¦ä½¿ç”¨ï¼Œä½ æ›´æ¨èå“ªä¸ªï¼Ÿ",
            "ä»ç”¨æˆ·è¯„ä»·è§’åº¦ï¼Œæœ€å¸¸è§çš„å·®è¯„ç‚¹æ˜¯ä»€ä¹ˆï¼Ÿæ€ä¹ˆè§„é¿ï¼Ÿ",
            "ä»è¿è¾“/åŒ…è£…/æ˜“æŸè§’åº¦ï¼Œå“ªä¸ªé£é™©æ›´å¤§ï¼Ÿ",
            "ç»™æˆ‘ä¸€ä¸ªæœ€ç»ˆè´­ä¹°å»ºè®®ï¼šä¹°å“ªä¸ªã€ä¹°å“ªä¸ªé…ç½®ã€ä¸ºä»€ä¹ˆã€‚",
            f"å¦‚æœæˆ‘å·²ç»æŠŠ {target_url} åŠ å…¥è´­ç‰©è½¦ï¼Œä½ å»ºè®®æˆ‘è¿˜çœ‹å“ªäº›å¯¹æ¯”ç‚¹å†ä¸‹å•ï¼Ÿ",
            "æœ€åï¼šç»™ä¸€ä¸ªä¸‰æ¡æ¸…å•å¼çš„è´­ä¹°å†³ç­–ä¾æ®ã€‚",
        ]
    else:
        base = [
            f"I'm on this product page ({title or current_url}). Can you compare it with this target product: {target_url}?",
            f"If I only buy one, should I pick {target_url} or this page's product? Why?",
            f"Who is {target_url} best for (use cases and people)?",
            "What are the key pros and cons of the target product?",
            "Which one is safer in durability/warranty/failure risk?",
            "If value-for-money is my top priority, which should I choose?",
            "If performance/experience is my top priority, which should I choose?",
            "Any differences in size/setup/maintenance cost?",
            "Any compatibility concerns (accessories, systems, interfaces, consumables)?",
            "If I can spend 20% more, what better alternatives should I consider (2-3 options)?",
            "If I need a cheaper option, what safe alternatives exist?",
            f"Summarize in one sentence why I should buy {target_url}.",
            "What are the must-check specs before buying? Any hidden pitfalls?",
            "Which is better for beginners?",
            "Which is better for heavy daily use?",
            "From reviews, what are the most common complaints and how to avoid them?",
            "Any shipping/packaging fragility concerns?",
            "Give a final recommendation: which to buy, which variant, and why.",
            f"If {target_url} is already in my cart, what last comparisons should I do before checkout?",
            "Finally: give me a 3-item decision checklist.",
        ]
    return base[:rounds]


def _generate_rufus_prompts(lang, url, title, bullets, min_rounds=3):
    if OpenAI is None:
        return _fallback_prompts(lang, url, title, bullets, min_rounds)

    api_key = os.getenv("CCIOI_API_KEY")
    if not api_key:
        return _fallback_prompts(lang, url, title, bullets, min_rounds)

    base_url = os.getenv("CCIOI_API_KEY", "https://api.deepseek.com")
    client = OpenAI(api_key=api_key, base_url=base_url)
    product_summary = f"title: {title}\nbullets: {bullets}\nurl: {url}"
    sys = (
        "You are a shopping assistant. Generate short, natural user questions "
        "to ask Rufus about a product. Output JSON array of strings only."
    )
    user = (
        f"Language: {'Chinese' if lang == 'zh' else 'English'}.\n"
        f"Need {max(min_rounds, 3)} to 5 questions.\n"
        f"Product info:\n{product_summary}"
    )
    try:
        resp = client.chat.completions.create(
            model="deepseek-chat",
            messages=[
                {"role": "system", "content": sys},
                {"role": "user", "content": user},
            ],
            stream=False,
        )
        content = resp.choices[0].message.content or "[]"
        prompts = json.loads(content)
        if isinstance(prompts, list) and prompts:
            return [str(p).strip() for p in prompts if str(p).strip()]
    except Exception as e:
        debug_log(f"LLM prompt generation failed: {e}")

    return _fallback_prompts(lang, url, title, bullets, min_rounds)


def _fallback_prompts(lang, url, title, bullets, min_rounds=3):
    base = []
    if lang == "zh":
        base = [
            f"æˆ‘åœ¨çœ‹è¿™ä¸ªäº§å“ï¼š{title or url}ï¼Œå®ƒé€‚åˆä»€ä¹ˆäººç¾¤ï¼Ÿ",
            "å®ƒå’ŒåŒç±»äº§å“ç›¸æ¯”æœ‰å“ªäº›ä¼˜ç¼ºç‚¹ï¼Ÿ",
            "æ—¥å¸¸ä½¿ç”¨ä¼šæœ‰å“ªäº›éœ€è¦æ³¨æ„çš„åœ°æ–¹ï¼Ÿ",
            "æœ‰æ²¡æœ‰æ›´é«˜æ€§ä»·æ¯”æˆ–æ›´è€ç”¨çš„æ›¿ä»£é€‰æ‹©ï¼Ÿ",
            "å¦‚æœé¢„ç®—æœ‰é™ï¼Œæœ€å€¼å¾—å…³æ³¨çš„æ ¸å¿ƒåŠŸèƒ½æ˜¯ä»€ä¹ˆï¼Ÿ",
        ]
    else:
        base = [
            f"I'm looking at this product: {title or url}. Who is it best for?",
            "What are the main pros and cons vs similar products?",
            "Any practical tips or downsides for daily use?",
            "Are there better-value alternatives I should consider?",
            "If I have a tight budget, what key feature matters most?",
        ]
    return base[: max(min_rounds, 3)]


def _extract_latest_response(page, selector_override=None):
    selectors = []
    if selector_override:
        selectors.append(selector_override)
    selectors.extend(
        [
            "#rufus-conversation-container .rufus-html-turn",
            "#rufus-conversation-container .rufus-text-subsections-with-avatar-branding-update",
            "#rufus-conversation-container .rufus-text-subsections-branding-update",
            "#nav-rufus-content .rufus-html-turn",
            "#nav-rufus-content .rufus-text-subsections-with-avatar-branding-update",
            "#nav-rufus-content .rufus-text-subsections-branding-update",
        ]
    )
    for selector in selectors:
        try:
            items = page.locator(selector)
            count = items.count()
            if count > 0:
                text = items.nth(count - 1).inner_text().strip()
                if text:
                    return text
        except Exception:
            continue
    return ""


def _wait_for_rufus_reply(page, selector_override=None, prev_text="", timeout_s=25):
    start = time.time()
    last = prev_text or ""
    while time.time() - start < timeout_s:
        try:
            status = page.locator("#rufus-status-announcer").first
            if status.count() > 0:
                _ = status.inner_text()
        except Exception:
            pass
        text = _extract_latest_response(page, selector_override)
        if text and text != last:
            stable = text
            stable_count = 0
            while stable_count < 3 and time.time() - start < timeout_s:
                time.sleep(0.5)
                newer = _extract_latest_response(page, selector_override)
                if newer == stable:
                    stable_count += 1
                else:
                    stable = newer
                    stable_count = 0
            if prev_text and stable.startswith(prev_text):
                delta = stable[len(prev_text):].strip()
            else:
                delta = stable
            return stable, delta
        time.sleep(0.5)
        last = text or last
    return last, ""


def _force_fill(page, selector, text):
    page.evaluate(
        """
        (sel, value) => {
          const el = document.querySelector(sel);
          if (!el) return false;
          el.scrollIntoView({block: 'center', inline: 'center'});
          el.focus();
          el.value = value;
          el.dispatchEvent(new Event('input', { bubbles: true }));
          el.dispatchEvent(new Event('change', { bubbles: true }));
          return true;
        }
        """,
        selector,
        text,
    )

# å¸¦æ—¥å¿—çš„å®‰å…¨æˆªå›¾
def save_screen(tag):
    try:
        path = f"{DEBUG_DIR}/{tag}_{int(time.time())}.jpg"
        pyautogui.screenshot(path)
        debug_log(f"Saved screenshot: {path}")
    except Exception as e:
        debug_log(f"Failed to save screenshot: {e}")

# å¸¦æ—¥å¿—çš„æŒ‰é’®æ£€æµ‹
def find_image(img, confidence=0.8):
    if not os.path.isabs(img):
        img = os.path.join(IMG_DIR, img)
    debug_log(f"Trying to find image: {img}")
    save_screen("before_find")   # æˆªå›¾å¸®åŠ©è°ƒè¯•

    try:
        location = pyautogui.locateCenterOnScreen(img, confidence=confidence)
        if location:
            debug_log(f"Image found at: {location}")
        else:
            debug_log("Image NOT found on screen")
        return location
    except Exception as e:
        debug_log(f"Image search error: {e}")
        return None

def _find_rufus_input_selector(page, rufus_selector=None):
    selectors = []
    if rufus_selector:
        selectors.append(rufus_selector)
    selectors.extend(
        [
            "#rufus-text-area",
            'textarea[placeholder*="Rufus"]',
            'input[placeholder*="Rufus"]',
            '[role="textbox"]',
            "textarea",
            'input[type="text"]',
        ]
    )
    for sel in selectors:
        try:
            if page.locator(sel).first.count() > 0:
                return sel
        except Exception:
            pass
    return None

def _ensure_rufus_visible(page):
    try:
        container = page.locator("#dpx-nice-widget-container").first
        if container.count() > 0:
            container.scroll_into_view_if_needed(timeout=5000)
            page.wait_for_timeout(500)
    except Exception:
        pass

def _open_rufus_ask_mode(page):
    """
    ç‚¹å¼€ Rufus çš„ Ask something elseï¼Œè¿›å…¥å¯èŠå¤©çŠ¶æ€
    """
    page.wait_for_selector("#dpx-nice-widget-container", timeout=15000)

    ask_btn = page.locator(
        "#dpx-nice-widget-container button.ask-pill"
    ).first

    if ask_btn.count() == 0:
        raise RuntimeError("Rufus Ask something else button not found")

    ask_btn.scroll_into_view_if_needed(timeout=5000)
    ask_btn.click()

    # ç­‰å¾… Rufus è¿›å…¥å¯¹è¯æ€ï¼ˆéå¸¸å…³é”®ï¼‰
    page.wait_for_timeout(1200)

def _chat_rufus_20_rounds(
    page,
    target_url,
    rufus_selector,
    rufus_response_selector,
    rounds=20,
    log_cb=None,
):
    current_url = page.url
    lang = _detect_language(page, current_url)
    title, bullets = _extract_product_info(page)
    
    # 1ï¸âƒ£ ç¡®ä¿ Rufus å¯è§
    _ensure_rufus_visible(page)

    # 2ï¸âƒ£ ç‚¹å¼€ Ask something elseï¼ˆæ ¸å¿ƒï¼‰
    _open_rufus_ask_mode(page)

    active_selector = _find_rufus_input_selector(page, rufus_selector)
    if not active_selector:
        raise RuntimeError("Rufus input box not found on product page")
    prompts = _generate_rufus_prompts_20(
        lang=lang,
        target_url=target_url,
        current_url=current_url,
        title=title,
        bullets=bullets,
        rounds=rounds,
    )

    last_answer = _extract_latest_response(page, rufus_response_selector)
    for i, prompt in enumerate(prompts):
        locator = page.locator(active_selector).first
        try:
            locator.scroll_into_view_if_needed(timeout=5000)
            locator.wait_for(state="visible", timeout=8000)
            locator.click()
            locator.fill(prompt)
        except Exception:
            # å¼ºåˆ¶å¡«å……å…œåº•
            try:
                _force_fill(page, active_selector, prompt)
            except Exception:
                page.keyboard.type(prompt)

        page.keyboard.press("Enter")
        if log_cb:
            log_cb(f"[å¯¹è¯] ç”¨æˆ·ï¼š{prompt}")
        answer_full, answer_delta = _wait_for_rufus_reply(
            page,
            selector_override=rufus_response_selector,
            prev_text=last_answer,
            timeout_s=25,
        )
        if answer_full:
            last_answer = answer_full
            if log_cb:
                preview = (answer_delta or answer_full).replace("\n", " ").strip()
                preview = preview[:200] + ("..." if len(preview) > 200 else "")
                log_cb(f"[å¯¹è¯] Rufusï¼š{preview}")
        _write_rufus_record(current_url, prompt, answer_full)

    return {
        "lang": lang,
        "title": title,
        "url": current_url,
        "rounds": len(prompts),
    }


# å¸¦æ—¥å¿—çš„ç‚¹å‡»
def click_image(img, confidence=0.8, timeout=10):
    debug_log(f"Searching for button [{img}] ... timeout={timeout}s")
    start = time.time()

    while time.time() - start < timeout:
        pos = find_image(img, confidence)
        if pos:
            debug_log(f"Clicking {img} at {pos}")
            pyautogui.moveTo(pos)
            pyautogui.click()
            return True

        debug_log(f"Not found yet... retrying...")
        time.sleep(1)

    debug_log(f"[ERROR] Timeout: Could not find {img}")
    save_screen("NOT_FOUND_" + img.replace(".jpg", ""))
    return False

# ============================================================
# TASKï¼šAmazon è‡ªåŠ¨åŒ–
# ============================================================
def _send_ws(loop, ws, payload):
    try:
        asyncio.run_coroutine_threadsafe(ws.send(json.dumps(payload)), loop)
    except Exception:
        pass

def _amazon_search_and_collect_links(page, keyword: str, max_pages=3, per_page_limit=20):
    links = []

    page.goto(AMAZON_HOME_URL, wait_until="domcontentloaded")
    page.wait_for_timeout(800)

    search_box = page.locator("input#twotabsearchtextbox").first
    if search_box.count() == 0:
        raise RuntimeError("Amazon search box not found")

    search_box.click()
    search_box.fill(keyword)
    page.keyboard.press("Enter")

    page.wait_for_load_state("domcontentloaded")

    # ğŸ”´ å…³é”®ï¼šç­‰ PUIS å¡ç‰‡å‡ºæ¥
    page.wait_for_selector(
        'span[data-action="puis-card-container-declarative"]',
        timeout=15000
    )
    page.wait_for_timeout(1000)

    for _ in range(max_pages):
        # âœ… åŸºäº PUIS çš„ selector
        anchors = page.locator(
            'span[data-action="puis-card-container-declarative"] a[href*="/dp/"]'
        )

        cnt = anchors.count()
        take = min(cnt, per_page_limit)

        for i in range(take):
            try:
                href = anchors.nth(i).get_attribute("href") or ""
                if "/dp/" not in href:
                    continue

                if href.startswith("/"):
                    href = "https://www.amazon.com" + href

                # å»æ‰å¤šä½™å‚æ•°ï¼Œé¿å…é‡å¤
                href = href.split("#")[0]

                if href not in links:
                    links.append(href)
            except Exception:
                continue

        # ç¿»é¡µ
        next_btn = page.locator("a.s-pagination-next").first
        if next_btn.count() == 0:
            break

        aria_disabled = next_btn.get_attribute("aria-disabled") or ""
        if aria_disabled.lower() == "true":
            break

        next_btn.click()
        page.wait_for_load_state("domcontentloaded")
        page.wait_for_timeout(1200)

    return links



def run_amazon_pollution(ws, task, loop):
    debug_log("===== START Amazon Pollution Task (NEW FLOW) =====")

    params = task.get("parameters", {})
    username = params.get("username")
    password = params.get("password")

    # ä½ çš„â€œç›®æ ‡å•†å“ urlâ€ï¼šå¸Œæœ› Rufus æ¨è/å¯¹æ¯”å®ƒ
    target_url = (params.get("url") or "").strip()

    login_url = params.get("login_url")
    keywords = params.get("keywords", [])

    rufus_selector = params.get("rufus_selector")
    rufus_response_selector = params.get("rufus_response_selector")

    # æ–°å¢å¯æ§å‚æ•°
    search_pages = int(params.get("search_pages", 3))                 # æ¯ä¸ªå…³é”®è¯ç¿»é¡µæ•°
    per_page_limit = int(params.get("per_page_limit", 20))            # æ¯é¡µé‡‡é›†æ•°
    max_products_total = int(params.get("max_products_total", 80))    # æ€»å•†å“ä¸Šé™ï¼ˆé˜²æ­¢æ— é™è·‘ï¼‰
    chat_rounds = int(params.get("chat_rounds", 20))                  # æ¯ä¸ªè¯¦æƒ…é¡µå¯¹è¯è½®æ•°

    debug_log(f"Params: username={username}, target_url={target_url}, keywords={keywords}")

    def _send_log(line):
        _send_ws(loop, ws, {"type": "TASK_LOG", "stream": "stdout", "line": line})

    try:
        os.makedirs(RUFUS_RUNS_DIR, exist_ok=True)
        run_id = datetime.now().strftime("%Y%m%d_%H%M%S")
        global RUFUS_RAW_FILE
        RUFUS_RAW_FILE = os.path.join(RUFUS_RUNS_DIR, f"rufus_{run_id}.csv")
        _send_log(f"æœ¬æ¬¡è®°å½•æ–‡ä»¶ï¼š{RUFUS_RAW_FILE}")
        with sync_playwright() as p:
            browser = p.chromium.launch(headless=False)
            context = browser.new_context()
            page = context.new_page()

            # ç›‘å¬
            def _maybe_http(url):
                return url.startswith("http://") or url.startswith("https://")

            page.on("console", lambda msg: _send_log(f"[æµè§ˆå™¨æ§åˆ¶å°] {msg.type}: {msg.text}"))
            page.on("pageerror", lambda err: _send_log(f"[é¡µé¢é”™è¯¯] {err}"))

            def _req_fail_msg(req):
                failure = req.failure
                if isinstance(failure, str):
                    detail = failure
                elif failure is None:
                    detail = "unknown"
                else:
                    detail = getattr(failure, "error_text", str(failure))
                return f"[è¯·æ±‚å¤±è´¥] {req.url} ({detail})"

            page.on("requestfailed", lambda req: _send_log(_req_fail_msg(req)))
            page.on(
                "response",
                lambda resp: _send_log(f"[é¡µé¢å“åº”] {resp.status} {resp.url}")
                if _maybe_http(resp.url) and resp.status >= 400
                else None,
            )

            # ============ 1) ç™»å½• ============
            signin_urls = [
                login_url,
                AMAZON_SIGNIN_URL,
                "https://www.amazon.com/gp/sign-in.html",
                AMAZON_HOME_URL,
            ]
            signin_urls = [u for u in signin_urls if u]

            _send_log("æ­£åœ¨æ‰“å¼€äºšé©¬é€Šç™»å½•é¡µ...")
            for u in signin_urls:
                _send_log(f"æ‰“å¼€é¡µé¢ï¼š{u}")
                page.goto(u, wait_until="domcontentloaded")
                page.wait_for_timeout(800)
                if page.locator("input#ap_email").first.count() > 0:
                    _send_log("æ£€æµ‹åˆ°ç™»å½•è¡¨å•ã€‚")
                    break
                if page.locator('a#nav-link-accountList').first.count() > 0:
                    _send_log("ç‚¹å‡» Account & Lists è¿›å…¥ç™»å½•ã€‚")
                    page.click('a#nav-link-accountList')
                    page.wait_for_timeout(800)
                if page.locator("input#ap_email").first.count() > 0:
                    _send_log("æ£€æµ‹åˆ°ç™»å½•è¡¨å•ã€‚")
                    break

            if page.locator("input#ap_email").first.count() == 0:
                raise RuntimeError("Signin form not found. Provide login_url in task params.")

            page.fill("input#ap_email", username or "")
            page.click("input#continue")
            _send_log("å·²æäº¤è´¦å·ï¼Œç­‰å¾…å¯†ç è¾“å…¥é¡µã€‚")

            try:
                page.wait_for_selector("input#ap_password", timeout=15000)
            except Exception:
                if page.locator("input[name='password']").first.count() == 0:
                    raise RuntimeError("Password field not found after email step.")

            if page.locator("input#ap_password").first.count() > 0:
                page.fill("input#ap_password", password or "")
            else:
                page.fill("input[name='password']", password or "")
            page.click("input#signInSubmit")
            page.wait_for_load_state("domcontentloaded")
            _send_log("å·²æäº¤å¯†ç ï¼Œç­‰å¾…ç™»å½•ç»“æœã€‚")

            # OTP
            otp_selector = None
            for sel in ["input#auth-mfa-otpcode", "input[name='otpCode']", "input[name='code']"]:
                if page.locator(sel).first.count() > 0:
                    otp_selector = sel
                    break

            if otp_selector:
                _send_log("éœ€è¦éªŒè¯ç ï¼Œè¯·åœ¨å‰ç«¯è¾“å…¥éªŒè¯ç ç»§ç»­ã€‚")
                _send_ws(loop, ws, {"type": "OTP_REQUIRED", "prompt": "Enter the 2FA code to continue login."})

                OTP_EVENT.clear()
                if not OTP_EVENT.wait(timeout=180):
                    raise RuntimeError("OTP timeout: no code received.")

                with OTP_LOCK:
                    otp_value = OTP_CODE
                if not otp_value:
                    raise RuntimeError("OTP missing.")

                page.fill(otp_selector, otp_value)
                if page.locator("input#auth-signin-button").first.count() > 0:
                    page.click("input#auth-signin-button")
                else:
                    page.keyboard.press("Enter")
                page.wait_for_load_state("domcontentloaded")
                _send_log("éªŒè¯ç å·²æäº¤ï¼Œç­‰å¾…ç™»å½•å®Œæˆã€‚")

            page.wait_for_timeout(1000)
            if page.locator("input#ap_email").first.count() > 0:
                raise RuntimeError("Login failed or still on signin page.")

            _send_log("ç™»å½•æˆåŠŸã€‚")

            if not target_url.startswith("http"):
                _send_log(f"[WARN] ç›®æ ‡å•†å“ url ä¸åˆæ³•ï¼š{target_url}ã€‚åç»­å¯¹è¯å°†æ— æ³•å¼•ç”¨ç›®æ ‡é“¾æ¥ã€‚")

            # ============ 2) å…³é”®è¯æœç´¢é‡‡é›†å•†å“é“¾æ¥ ============
            all_links = []
            if not keywords:
                _send_log("[WARN] keywords ä¸ºç©ºï¼Œå°†åªå¯¹ target_url è‡ªå·±åšä¸€æ¬¡å¯¹è¯ï¼ˆå¦‚æœå®ƒæ˜¯å•†å“é¡µï¼‰ã€‚")
                if target_url.startswith("http"):
                    all_links = [target_url]
            else:
                for kw in keywords:
                    kw = str(kw).strip()
                    if not kw:
                        continue
                    _send_log(f"å¼€å§‹ç«™å†…æœç´¢å…³é”®è¯ï¼š{kw}")
                    links = _amazon_search_and_collect_links(
                        page,
                        keyword=kw,
                        max_pages=search_pages,
                        per_page_limit=per_page_limit,
                    )
                    _send_log(f"å…³é”®è¯ [{kw}] é‡‡é›†åˆ°å•†å“é“¾æ¥ï¼š{len(links)} æ¡")
                    for lk in links:
                        if lk not in all_links:
                            all_links.append(lk)
                        if len(all_links) >= max_products_total:
                            break
                    if len(all_links) >= max_products_total:
                        _send_log(f"å·²è¾¾åˆ°æ€»å•†å“ä¸Šé™ {max_products_total}ï¼Œåœæ­¢ç»§ç»­é‡‡é›†ã€‚")
                        break

            _send_log(f"æ€»è®¡å°†å¤„ç†å•†å“è¯¦æƒ…é¡µï¼š{len(all_links)} ä¸ª")
            if not all_links:
                _send_log("âš ï¸ æœç´¢æœªé‡‡é›†åˆ°å•†å“ï¼Œæš‚åœæµè§ˆå™¨ 60 ç§’ä¾›äººå·¥æŸ¥çœ‹")
                time.sleep(60)
            # ============ 3) é€ä¸ªå•†å“è¯¦æƒ…é¡µï¼š20 è½® Rufus å¯¹è¯ ============
            ok = 0
            fail = 0
            def is_page_dead_error(e: Exception) -> bool:
                msg = str(e).lower()
                return (
                    "has been closed" in msg
                    or "target page" in msg
                    or "browser has been closed" in msg
                    or "context" in msg
                )
            for idx, product_url in enumerate(all_links):
                _send_log(f"æ‰“å¼€å•†å“ ({idx+1}/{len(all_links)}): {product_url}")
                page = None

                try:
                    page = context.new_page()

                    page.goto(product_url, wait_until="domcontentloaded", timeout=60000)
                    page.wait_for_timeout(3000)

                    info = _chat_rufus_20_rounds(
                        page=page,
                        target_url=target_url,
                        rufus_selector=rufus_selector,
                        rufus_response_selector=rufus_response_selector,
                        rounds=chat_rounds,
                        log_cb=_send_log,
                    )

                    ok += 1
                    _send_log(f"å®Œæˆå•†å“ï¼š{info.get('title') or product_url}")

                except Exception as e:
                    fail += 1
                    _send_log(f"[ERROR] å•†å“é¡µå¤„ç†å¤±è´¥ï¼š{product_url} | {e}")

                    if is_page_dead_error(e):
                        _send_log("âš ï¸ page/context å·²å¤±æ•ˆï¼Œé‡å»º context")
                        try:
                            context.close()
                        except:
                            pass
                        context = browser.new_context()

                finally:
                    if page:
                        try:
                            page.close()
                        except:
                            pass


            _send_log(f"ä»»åŠ¡ç»“æŸï¼šæˆåŠŸ {ok} ä¸ªï¼Œå¤±è´¥ {fail} ä¸ª")
            browser.close()

        debug_log("===== END Amazon Pollution Task (NEW FLOW) =====")

    except Exception as e:
        debug_log(f"[FATAL ERROR] {e}")
        traceback.print_exc()
        save_screen("fatal_error")
        _send_ws(loop, ws, {"type": "TASK_LOG", "stream": "stderr", "line": f"Agent fatal error: {e}"})


# ============================================================
# WebSocket Agent
# ============================================================
async def run_agent():
    while True:
        debug_log(f"Connecting to server {SERVER_WS} ...")
        try:
            async with websockets.connect(SERVER_WS) as ws:
                debug_log("Connected to server.")

                # å¿ƒè·³çº¿ç¨‹
                async def heartbeat():
                    while True:
                        try:
                            await ws.send(json.dumps({"type": "HEARTBEAT"}))
                        except:
                            return
                        await asyncio.sleep(5)

                asyncio.create_task(heartbeat())

                while True:
                    msg = await ws.recv()
                    data = json.loads(msg)

                    debug_log(f"Received message: {data}")

                    # æ”¯æŒæ²¡æœ‰ typeï¼Œåªé  task åˆ¤æ–­
                    if data.get("task") == "AMAZON_POLLUTION":
                        debug_log("Trigger AMAZON_POLLUTION task")
                        loop = asyncio.get_running_loop()
                        threading.Thread(
                            target=run_amazon_pollution,
                            args=(ws, data, loop),
                            daemon=True,
                        ).start()
                        continue
                    if data.get("type") == "OTP_RESPONSE":
                        code = str(data.get("otp", "")).strip()
                        with OTP_LOCK:
                            global OTP_CODE
                            OTP_CODE = code
                        OTP_EVENT.set()
                        debug_log("Received OTP code from client.")
                        continue

        except Exception as e:
            debug_log(f"Connection lost: {e}, retrying...")
            await asyncio.sleep(3)


if __name__ == "__main__":
    asyncio.run(run_agent())
